{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "718c5295-c3b2-4066-b52c-275723acd98b",
   "metadata": {},
   "source": [
    "# Using neural_network with circular data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525b7c11-012f-4210-abe3-fcda787f1382",
   "metadata": {},
   "source": [
    "In this notebook, we use the `neural_network` package to predict whether datapoints lie inside or outside the unit disc in the $x-y$ plane. Note that this notebook follows the same example as within the `examples/classification/circle` directory if you prefer not to use Jupyter notebook. Here we assume that `neural_network` is pip installed onto your machine. If you have not done so, please see `README.md` in the python package for installation instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e28d0f7-9df3-43bc-bb13-2fb2669bb245",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d13686-b009-48fd-b51e-efbef5c50b1a",
   "metadata": {},
   "source": [
    "Below, we ensure that the `Plotter` class will show all the plots for this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc55a56-bd7a-4fb5-9840-f2e4150e91d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neural_network import Plotter\n",
    "Plotter.show_plots = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8cfd917-194b-4fdd-9850-6d4e19a24740",
   "metadata": {},
   "source": [
    "## Generating our data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c991eb-00df-43fc-817f-93e21e0fcef3",
   "metadata": {},
   "source": [
    "The first step is to generate some labelled data, with points inside the unit disc belonging to one class, and points outside belonging to another. This will be our ground truth data, and we can use a `UniformDataGenerator` to generate some uniformly distributed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392ee971-3cb3-4e9c-91a5-7c9acf265992",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neural_network import UniformDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002dc99d-4cdc-484b-b51e-6f8e701c493c",
   "metadata": {},
   "source": [
    "`UniformDataGenerator` takes the following arguments to its constructor method:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d59aa4-7fd9-49c4-9c92-097d6f4874a8",
   "metadata": {},
   "source": [
    "| argument         | type          | description|\n",
    "|------------------|---------------|---------------|\n",
    "| `function`       | `Callable`    | This `function` takes in the coordinates of the datapoint as arguments, and returns either a discrete class or value for classification and regression problems respectively.|\n",
    "| `num_datapoints` | `int`         | The number of datapoints to be generated.|\n",
    "| `lower_bounds`          | `List[float]` | The lower bound of each coordinate.|\n",
    "| `upper_bounds`       | `List[float]` | The upper bound of each coordinate.|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc6c2a4-b5a8-4188-9443-f70e20882971",
   "metadata": {},
   "source": [
    "For our example, the `function` will take `x_1` and `x_2` as arguments and return a string for whether the point is `\"Inside\"` or `\"Outside\"` the unit disc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8076cb-f345-453f-afef-bad19ce27eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier(x_1: float, x_2: float) -> str:\n",
    "\n",
    "    if x_1**2 + x_2**2 < 1:\n",
    "        return \"Inside\"\n",
    "    else:\n",
    "        return \"Outside\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fecdabbf-834f-4e5a-94c6-7313cffa90bd",
   "metadata": {},
   "source": [
    "Now we can generate a number of datapoints, and create a scatter plot using `generator.plot_datapoints`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d634f71b-8641-45a1-8d9e-1fab317aa3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = UniformDataGenerator(classifier, num_datapoints=400, lower_bounds=[-1.0, -1.0], upper_bounds=[1.0, 1.0])\n",
    "df = generator()\n",
    "generator.plot_datapoints(title=\"circle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb26117-f89c-4066-acb5-549b24a79494",
   "metadata": {},
   "source": [
    "We can then save this dataframe to a .csv file to store it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5772a213-1925-4717-81f5-bdea928cba4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.write_to_csv(title=\"circle_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b439cb80-f4d6-48f0-abc9-07f66965940d",
   "metadata": {},
   "source": [
    "## Splitting data and constructing the network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc7a3ba-eb2d-4fd2-8c66-95e4306fc78f",
   "metadata": {},
   "source": [
    "Now that we have some data to work with, we can begin learning! Our goal is to train a neural network to learn the patterns of the data and be able to accurately predict whether a point lies inside or outside the unit disc. In order to do this, we will need to split our data into a training set, validation set and testing set. Below is a brief description of what is involved in each phase."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39cee709-51bb-4c0e-bc64-fc12fd1415a2",
   "metadata": {},
   "source": [
    "|phase|description|common percentage of total data|\n",
    "|---|-------|---|\n",
    "|training|We train our network on the majority of the data. For this phase, we send our data through the network to generate a prediction of the class, and then update the network's weights and biases depending on how good the prediction is (back propagation). We iterate this process over a number of epochs.|80%|\n",
    "|validation|During training, we pass our validation set through the network WITHOUT doing back propagation to see how well the network performs on unseen data at each epoch.|10%|\n",
    "|testing|Finally, after we have run all epochs of training and validation, we test our remaining data on the network to see how well the network performs after training has finished. We use this testing data to generate metrics of how well the network has performed.|10%|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3116032c-2b43-421a-857c-7b9043f90801",
   "metadata": {},
   "source": [
    "We can make use of a helper class to randomly split our data up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee97486-da91-477f-81e6-c01c8e7a7e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neural_network import DataSplitter\n",
    "data_splitter = DataSplitter(path=\"circle_data.csv\", proportions=[8, 1, 1])\n",
    "training_data, validation_data, testing_data = data_splitter.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d3b9e9-e4b2-4524-943b-a784d65274dc",
   "metadata": {},
   "source": [
    "Our next step is to construct the `network` itself. Below is a list of parameters that can be passed to the `Network` constructor. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3adbc7c-090e-46fa-a20b-ce5ff1e4b356",
   "metadata": {},
   "source": [
    "| parameter           | type        | description                                                                                               | default  |\n",
    "|---------------------|-------------|-----------------------------------------------------------------------------------------------------------|----------|\n",
    "| `num_features`      | `int`       | The number of features (x coordinates) per datapoint.                                                     | ---      |\n",
    "| `num_hidden_layers` | `int`       | The number of hidden layers of the network.                                                               | ---      |\n",
    "| `neuron_counts`     | `List[int]` | The number of neurons in each hidden layer.                                                               | ---      |\n",
    "| `num_classes`       | `int`       | The number of classes in the data for a classification problem. This parameter is ignored for regression. | `2`      |\n",
    "| `regression`        | `bool`      | `True` corresponds to regression, `False` is classification.                                              | `False`  |\n",
    "| `leak`              | `float`     | The leak for the ReLU function. Choose `0` for no leak.                                                   | `0.01`   |\n",
    "| `learning_rate`     | `float`     | The learning rate for the network.                                                                        | `0.01`   |\n",
    "| `adaptive`          | `bool`      | Whether we wish to have an adaptive learning rate or not (using momentum).                                | `False`  |\n",
    "| `gamma`             | `float`     | The adaptive learning rate parameter. This is ignored if `adaptive` is `False`                            | `0.9`    |\n",
    "| `he_weights`        | `bool`      | Whether we wish to initialise the weights of the network according to He or not [$^{[1]}$](Sources).                     | `False`  |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343e0e83-9847-4b43-bde6-f0f838f63d75",
   "metadata": {},
   "source": [
    "For the circle data, we have 2 features (x_1, x_2) and 2 classes (inside, outside), but we are free to specify the rest. We will\n",
    "mostly use defaults, but have some of the booleans turned on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bef38e8-94a5-4931-a9d9-6963710b7e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neural_network import Network\n",
    "network = Network(num_features=2, num_hidden_layers=3, neuron_counts=[4, 4, 4],\n",
    "                  adaptive=True, he_weights=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f013a3ac-8493-41bb-976e-0ca8978e89f5",
   "metadata": {},
   "source": [
    "We can use `network.visualise_network` (which uses the `networkx` package) to visualise the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec82c9d-7f94-47ca-8dcb-1abea30377fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "network.visualise_network(\"circle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131db125-da5c-4251-af50-b8e8e8eb868f",
   "metadata": {},
   "source": [
    "We can see the input layer, three hidden layers and an output layer for this network."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78cfc6b2-d04d-4504-8a3a-05e1bc82f956",
   "metadata": {},
   "source": [
    "## Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dbadf27-5346-46c6-8c35-296269dab87d",
   "metadata": {},
   "source": [
    "Now we are ready to start using the learners - `Trainer`, `Validator` and `Tester`. We can pass the following parameters to the learner's constructors:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c93c8a-4858-45d8-b05a-7f35edd6a91c",
   "metadata": {},
   "source": [
    "| parameter    | type           | description                                           | default |\n",
    "|--------------|----------------|-------------------------------------------------------|---------|\n",
    "| `network`    | `Network`      | Our network from above.                               | ---     |\n",
    "| `data`       | `pd.DataFrame` | The data for the specific phase.                      | ---     |\n",
    "| `batch_size` | `int`          | The batch size we wish to use.                        | ---     |\n",
    "| `weighted`   | `bool`         | Whether we want weighted or unweighted batches.       | `False` |\n",
    "| `validator`  | `Validator`    | **TRAINER ONLY** - the already instantiated validator.| `None`  |\n",
    "| `num_epochs` | `int`          | **TRAINER ONLY** - the number of epochs to train for. | ---     |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d8c41e-5540-4d7d-b081-77509a82ff24",
   "metadata": {},
   "source": [
    "During each epoch, we will send the data through in batches of a fixed `batch_size`, and then back-propagate through the network after each batch. For unweighted batches, we simply randomly partition the dataset into batches and the network will see all the data each epoch. For weighted batches, instead we give each class a weight depending on how many elements there are and then use the inverse of these weights as proportions for choosing in\n",
    "the batches."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0462b65c-66da-4e6d-9265-5011e3dafbe0",
   "metadata": {},
   "source": [
    "This way, for classes of quite different sizes, we over-sample from smaller classes and under-sample from larger classes to give the network\n",
    "a better chance of learning the patterns in the data. For our example, there are many more points **inside** the circle than **outside**, so\n",
    "points on the **outside** have a greater chance of being picked for the batch when we choose to set `weighted=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db52ccb2-ebd9-4d72-9456-09c7f7e65bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neural_network import Validator, Trainer, Tester\n",
    "validator = Validator(network, validation_data, batch_size=10)\n",
    "trainer = Trainer(network, training_data, num_epochs=1000, batch_size=16,\n",
    "                  weighted=True, validator=validator)\n",
    "tester = Tester(network, testing_data, batch_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f0fa93-e962-4cfd-9724-4ebb3c486dea",
   "metadata": {},
   "source": [
    "We can now run the `trainer`! Note this also runs the `validator`, and we will get updates on training and validation loss throughout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cdcdc31-b24b-45aa-8856-41ec4985615d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainer.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f02e670-7c1c-40bf-acc3-aacb1b2e834d",
   "metadata": {},
   "source": [
    "We lastly run the `tester` to see how well the network does on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417f3f94-69e9-453d-9542-7c70f1c14537",
   "metadata": {},
   "outputs": [],
   "source": [
    "tester.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b0ac8b-fcb4-4098-92de-603b4fc7bd2b",
   "metadata": {},
   "source": [
    "## Plotting the results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ec0590-09f6-4b2e-8df4-80346e0e5f5c",
   "metadata": {},
   "source": [
    "There are a few different evaluation plots we can use to see how well the network has performed. Firstly, we can plot the loss over\n",
    "time for training and validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b923a7-6d6f-418f-9290-0018b70a66a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.generate_loss_plot(title='circle')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4071efa1-d015-4577-b53b-faf34ee75ba6",
   "metadata": {},
   "source": [
    "Next, we can see some scatter plots for the predicted classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d352cad-a9dc-49b6-ad05-c8514cf83d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.generate_scatter(title='circle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303a830d-254c-4d58-bbfd-c6671ec16196",
   "metadata": {},
   "outputs": [],
   "source": [
    "validator.generate_scatter(title='circle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4146b6c-1c78-42f1-b455-3475a5dc175e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tester.generate_scatter(title='circle')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4352e547-d414-47da-81b2-be4f4f62fb11",
   "metadata": {},
   "source": [
    "Finally, we can print out the confusion matrix and dice scores for the testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6446123-f52f-4df4-96b8-adfda35ba047",
   "metadata": {},
   "outputs": [],
   "source": [
    "tester.generate_confusion()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca50fd91-dd56-49d4-acad-f92552e5fc4a",
   "metadata": {},
   "source": [
    "## Sources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219e53d9-9c60-4e99-a604-774ae10dadb2",
   "metadata": {},
   "source": [
    "$^{[1]}$: K. He et al., [Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification](https://openaccess.thecvf.com/content_iccv_2015/html/He_Delving_Deep_into_ICCV_2015_paper.html), Proceedings of the IEEE International Conference on Computer Vision (ICCV), 2015, pp. 1026-1034"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
